{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c24c65e-00ed-49c0-b77a-c2db889470a6",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b060d4-8121-4f17-9a3b-e864f26a4b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from trl import DPOTrainer\n",
    "\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb51d7-001d-4e5c-983a-ae21a68ef77f",
   "metadata": {},
   "source": [
    "### Полезные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "400be7b0-a986-4409-be46-913a781a3ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1bdb76-ca10-4745-b8ec-df74646989f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from collections import defaultdict\n",
    "\n",
    "def token_entropy(generations, tokenizer):\n",
    "    stats = defaultdict(int)\n",
    "    num_tokens = 0\n",
    "    for example in tqdm(generations, desc=\"Evaluating\"):\n",
    "        tokens = tokenizer.encode(example)\n",
    "        for t in tokens:\n",
    "            if t == tokenizer.pad_token_id:\n",
    "                continue\n",
    "            stats[t] += 1\n",
    "            num_tokens += 1\n",
    "    for k in stats.keys():\n",
    "        stats[k] /= num_tokens\n",
    "    return entropy(list(stats.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ba282-166b-480c-ab9e-eeaea1c29871",
   "metadata": {},
   "source": [
    "Кажется, что эта функция и так достаточно неплохо оценивает разнообразие, я и не знаю, что можно здесь придумать лучше энтропии, ведь это буквально то, что она должна делать по определению - оценивать разнообразие. Можно было бы попробовать подсчитать в лоб долю испольхованных слов словаря или долю разных токенов в предсказании, но это какие-то ни на чём не основанные вещи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aaa4b8-998f-420d-b181-2f1e1b8933fe",
   "metadata": {},
   "source": [
    "### Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2276ea-d5d0-4983-9a38-5bb785b660e0",
   "metadata": {},
   "source": [
    "#### 1.1 Проверка генерации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa58f6-c3bd-4f4e-9059-1f56e78d9e2c",
   "metadata": {},
   "source": [
    "Ниже пройдёмся по всем пунктам, что были в первой части. Сперва нужно достать sft-модель и разобраться, как она работает. Для этого достаточно ознакомиться с интерфейсом с huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640f0e85-3e66-41b2-a7cc-89ee71d219fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"lvwerra/gpt2-imdb\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    model_name, padding_side='left',\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    model_name, pad_token_id=tokenizer.pad_token_id,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd053c-196a-467a-8ca4-853af69e28fd",
   "metadata": {},
   "source": [
    "Ниже простенькая функция генерации. Параметры я подобрал такие, чтобы получалось что-то более-менее осмысленное, но не слишком длинное, а то долго обучаться. Сразу же добавил дефолтные опции для генерации положительных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f8865f-01c4-4f40-9786-4bf13513655a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_from_input(\n",
    "    inp=\"\",\n",
    "    debug=False,\n",
    "    naive_guidance=None,\n",
    "    **generation_config\n",
    "):\n",
    "    guidance_dict = {\n",
    "        \"positive\": f\"Good Review: {inp}\",\n",
    "        \"negative\": f\"Negative Review: {inp}\",\n",
    "        None: \"...\" if inp == \"\" else inp\n",
    "    }\n",
    "    inp = guidance_dict[naive_guidance].rstrip()\n",
    "    input_ids = tokenizer.encode(\n",
    "        inp, return_tensors='pt',\n",
    "        add_special_tokens=False,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    beam_output = model.generate(\n",
    "        input_ids, do_sample=True, **generation_config\n",
    "    ).to(device)\n",
    "    output = tokenizer.decode(\n",
    "        beam_output[0], skip_special_tokens=False,\n",
    "        clean_up_tokenization_spaces=False,\n",
    "    )\n",
    "    if debug:\n",
    "        print(output)\n",
    "    return \".\".join(output.split(\".\")[:-1]) + \".\"\n",
    "\n",
    "generation_config = dict(\n",
    "    top_k=50,\n",
    "    num_beams=5,\n",
    "    max_length=100,\n",
    "    early_stopping=True,\n",
    "    no_repeat_ngram_size=2,\n",
    "    renormalize_logits=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c581807-17cd-4377-aba7-f2556109dfba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'... I am very glad I bought this one.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_from_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e603c2df-5560-460e-96aa-b7cc8dcbfdd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Review: After reading all the other reviews , i want to give credit where credit is due.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_from_input(naive_guidance=\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff64be-e096-47f6-8080-2da0627f96b1",
   "metadata": {},
   "source": [
    "Кажется, всё работает. Дальше нужна модель, которая будет эти отзывы оценивать, тоже из задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c57a3a0-7d98-4a2d-9a15-93418e2e2a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"lvwerra/distilbert-imdb\"\n",
    "\n",
    "clf_tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "clf = DistilBertForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e2f42-c278-4dce-8fa1-ffaae8077882",
   "metadata": {},
   "source": [
    "Сразу же добавлю функцию классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eee0868-5aa1-4975-bc4e-ba603620b9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify(inp, as_proba=True):\n",
    "    inputs = clf_tokenizer(inp, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = clf(**inputs).logits\n",
    "    if as_proba:\n",
    "        logits = sigmoid(logits)\n",
    "    return logits[:, 1].cpu().numpy()\n",
    "\n",
    "multiclassify = np.vectorize(classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2cf9de-df8b-466c-8c39-56c8fe966b7c",
   "metadata": {},
   "source": [
    "На тему того, как можно генерироать более положительные отзывы, я не придумал ничего лучше, чем модифицировать промпт. \n",
    "\n",
    "1. У меня была мысль с более хитрым бим сёрчем - можно было бы оставлять такие опции, которые не только более вероятны, но и имеют положительную тональность. Это можно было бы сделать даже при помощи той же гпт2, если взять другую архитектуру, но пришлось бы переделывать функцию генерации, это во-первых не очень очевидно, во-вторых будет не совсем эффективно вроде как, потокенная генерация дело долгое. В общем, показалось, что это просто слишком сложно для самого начала задания, ответ наверное должен быть проще. Если бы я мог решить эту проблему на этапе бим сёрча, всё задание ниже не имело бы смысла\n",
    "\n",
    "2. Была мысль с тупой генерацией как можно большего числа примеров, затем осталось бы выделить из них положительные и радоваться жизни, но это не непосредственно модификация модели\n",
    "\n",
    "3. Файн-тюн это тоже опция, конечно, но это фактически попытка решить нашу задачу, тоже не то\n",
    "\n",
    "4. Модифицировать промпт это тоже не совсем понятная вещь, потому что прописать можно много всего разного. Я остановился на 'Good Review', он вполне себе даёт результаты, как будет видно ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96c32223-ecfa-45de-9a76-7c88f9378da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53372973, 0.20303504, 0.68123496], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(69)\n",
    "\n",
    "n_samples = 30\n",
    "samples = np.empty((n_samples, 3), dtype=object)\n",
    "for i in trange(n_samples):\n",
    "    for j, guidance in enumerate([None, \"negative\", \"positive\"]):\n",
    "        samples[i, j] = generate_from_input(naive_guidance=guidance, **generation_config)\n",
    "\n",
    "scores = multiclassify(samples)\n",
    "scores.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b647b-ed66-4f23-8347-9e02da0e1544",
   "metadata": {},
   "source": [
    "Тут уже с вероятностями классов. Видно, что третий столбец, именно там были положительные промпты, оказывается в среднем более позитивным, значит с этим и будем работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f0b34b1-6dc3-4884-ab15-755911386420",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374aaccce03e4571b4c94fd495223500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_everything(69)\n",
    "\n",
    "n_samples = 10000\n",
    "samples = np.empty(n_samples, dtype=object)\n",
    "for i in trange(n_samples):\n",
    "    samples[i] = generate_from_input(naive_guidance=\"positive\", **generation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7e822-87a2-4aec-adf4-926313b66479",
   "metadata": {},
   "source": [
    "Дальше нужно каждый из них оценить, благо это не очень долго. Средний реворд действительно больше 0, всё в целом нормально, разнообразие тоже посчитано внизу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "735d4c88-de51-43a5-83a1-fed075a30c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46090737, 2.9355285)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = np.vectorize(lambda x: classify(x, False))(samples)\n",
    "reward.mean(), reward.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62be1dd6-3536-4c88-88cd-d5b16aa506f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a452d0daa24f3fa2ff0df0d4aa5325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.73228185758214"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_entropy(samples, clf_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7e8f0-3c0e-4431-9f65-c2cade8272a8",
   "metadata": {},
   "source": [
    "Все отзывы и реворды я на всякий случай сохранил, так что можно не прогонять всё, что выше, а сразу переходить к следующему пункту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f73dd6-e6de-4438-a221-3255bd2315c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = np.load(\"samples.npy\", allow_pickle=True)\n",
    "reward = np.load(\"rewards.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88335b05-35b9-4b8b-87b1-338f93cf1d5a",
   "metadata": {},
   "source": [
    "Я возьму за хорошие пары все те, у которых реворд больше 2, кажется, что они достаточно положительные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab7f3d4-3cab-4ce1-b585-7c3a42f08336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "winner = reward > 2\n",
    "loser = (0 < reward) & (reward < 2)\n",
    "\n",
    "winner_samples, loser_samples = samples[winner], samples[loser]\n",
    "winner_reward, loser_reward = reward[winner], reward[loser]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0771ec6-4047-42b8-b825-41a95a68f9e9",
   "metadata": {},
   "source": [
    "Останется только собрать из них датасет и можно будет приступать к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34bec805-15a1-4b84-b20f-657d91152892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dataset(n_samples):\n",
    "    \n",
    "    dpo_dataset = defaultdict(list)\n",
    "\n",
    "    winner_sample = np.random.choice(winner_samples, size=n_samples)\n",
    "    loser_sample = np.random.choice(loser_samples, size=n_samples)\n",
    "    prompts = [\"Good Review:\"]*n_samples\n",
    "\n",
    "    dpo_dataset[\"prompt\"] = prompts\n",
    "    dpo_dataset[\"chosen\"] = winner_sample  \n",
    "    dpo_dataset[\"rejected\"] = loser_sample\n",
    "\n",
    "    dpo_dataset = Dataset.from_dict(dpo_dataset)\n",
    "    dpo_dataset = dpo_dataset.map(batched=True)\n",
    "    \n",
    "    return dpo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1cd8dff-97e2-46fc-be9f-4ad056047ace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5243ebbf2cd5438ebd6d8b4c2a12db89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e892eda73bf8417eb3361e59d3fe923f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb26abc435d4083abe195ddcccf117d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seed_everything(69)\n",
    "\n",
    "dataset = generate_dataset(int(1e3))\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset.save_to_disk(\"dataset.hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be47f88-6d65-40b5-8264-c2c409e4a0ac",
   "metadata": {},
   "source": [
    "Всю логику обучения я оформил в отдельном классе, потому что вызывать её придётся очень часто, можно с этим ознакомиться там. Вкратце: загружаем датасет, копируем модельки, запускаем `DPOTrainer` с нужными параметрами, обучаем, сохраняем метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d03655-7d2e-4582-a595-324d617045e0",
   "metadata": {},
   "source": [
    "#### 1.2 Сравнение лоссов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f092e3-f565-4212-b468-ec3dbf5c6118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 02:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-121.575462</td>\n",
       "      <td>-72.020729</td>\n",
       "      <td>-42.489925</td>\n",
       "      <td>-37.603886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-158.835388</td>\n",
       "      <td>-71.110535</td>\n",
       "      <td>-43.824852</td>\n",
       "      <td>-36.914539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-165.572632</td>\n",
       "      <td>-72.145340</td>\n",
       "      <td>-44.334946</td>\n",
       "      <td>-37.273350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93115856276749b59ab75271819dc950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.783983918485955"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.train(loss_type=\"hinge\")\n",
    "pipe.evaluate(\"hinge\", n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e95c1a5-983f-4d2f-b768-c0da5c354bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is a lot of fun to watch. The acting is good, the story is well written, and the characters are likable. I think this is one of the best movies I've seen in a long time.\n",
      "This movie is one of the best movies I've seen in a long time. The acting is great, the story is well written, and the characters are likable. I highly recommend this movie to anyone who is looking for a good movie.\n",
      "This movie is a great example of how to make a good horror movie. The acting is great, the story is well written, and the characters are likable. I highly recommend this movie to anyone who is looking for a horror film.\n"
     ]
    }
   ],
   "source": [
    "# hinge\n",
    "\n",
    "for _ in range(3):\n",
    "    print(pipe.generate_from_input(\"This movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426eb5b2-28eb-424c-a527-a3521135587a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 02:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-121.575447</td>\n",
       "      <td>-72.020729</td>\n",
       "      <td>-42.489937</td>\n",
       "      <td>-37.603867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-158.835342</td>\n",
       "      <td>-71.110527</td>\n",
       "      <td>-43.824833</td>\n",
       "      <td>-36.914505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-165.572571</td>\n",
       "      <td>-72.145332</td>\n",
       "      <td>-44.334923</td>\n",
       "      <td>-37.273323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb713637a22406ab19484bc300c92a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.783983918485955"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.train(loss_type=\"sigmoid\")\n",
    "pipe.evaluate(\"sigmoid\", n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3dba69-5368-4f43-bdb0-4a980dde0545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie great this movie. It is great. The acting is good, the story is well told, and the special effects are very good. This is one of the best movies I have seen in a long time.\n",
      "This movie great this movie. It is great. The acting is good, the story is well told, and the characters are well developed. This is one of the best movies I have seen in a long time.\n",
      "This movie great this movie. It is great. The acting is good, the story is well told, and the special effects are very good. This is one of the best movies I have seen in a long time.\n"
     ]
    }
   ],
   "source": [
    "# sigmoid\n",
    "\n",
    "for _ in range(3):\n",
    "    print(pipe.generate_from_input(\"This movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc175c5-b5af-4e6a-ab18-f1062658ad1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>experiment</th>\n",
       "      <th>hinge</th>\n",
       "      <th>sigmoid</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <td>2.802011</td>\n",
       "      <td>2.834603</td>\n",
       "      <td>2.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diversity</th>\n",
       "      <td>3.741267</td>\n",
       "      <td>3.731363</td>\n",
       "      <td>4.732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "experiment     hinge   sigmoid   best\n",
       "reward      2.802011  2.834603  2.935\n",
       "diversity   3.741267  3.731363  4.732"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_dfs = [\"sigmoid\", \"hinge\"]\n",
    "summary = pd.concat([pd.read_csv(f\"{df}.csv\") for df in all_dfs])\n",
    "summary = summary.groupby(\"experiment\").mean(\"reward\").sort_values(\"reward\")\n",
    "summary.loc[\"best\"] = [2.935, 4.732]\n",
    "summary.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd87c3-42ad-4718-aa1e-90b7deb984a6",
   "metadata": {},
   "source": [
    "Как можно заметить, между лоссами нет принципиальной разницы, как обычно её нет при обучении свм и логрега. В общем и целом можно заметить, что средний реворд действительно вырос и очень даже неплохо, но при этом сильно пострадало разнообразие текстов. Можно заметить, что они все почти одинаковые, это может быть не очень хорошо, но быть может и обучение было проведено тоже не идеально"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b4fc8-68f3-497f-ae19-889921bf45c5",
   "metadata": {},
   "source": [
    "### Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5f857-1883-4ffd-9dc7-259db3f45ae8",
   "metadata": {},
   "source": [
    "Здесь нужно внимательно посмотреть в статью и увидеть там 2 вещи\n",
    "\n",
    "1. Лосс в обобщённом виде, где $f'$ это производная произвольной дивергенции, в `DPOTrainer` это обратная КЛ-дивергенция, её мы и будем менять"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7c638-2a3f-41de-aaa2-0360b02b56e6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\theta}, \\mathcal{D})=\\mathbb{E}_{\\left(x, y_w, y_l\\right) \\sim \\mathcal{D}}\\left[-\\log \\sigma\\left(\\beta f^{\\prime}\\left(\\frac{\\pi_{\\boldsymbol{\\theta}}\\left(y_w | x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_w | x\\right)}\\right)-\\beta f^{\\prime}\\left(\\frac{\\pi_{\\boldsymbol{\\theta}}\\left(y_l | x\\right)}{\\pi_{\\mathrm{ref}}\\left(y_l  | x\\right)}\\right)\\right)\\right] .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc0cae-ca24-459f-9cbb-f55b199af231",
   "metadata": {},
   "source": [
    "2. Это табличка, где все производные уже любезно подсчитаны за нас, дальше остаётся только это дело закодить и вставить в класс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975f1fe-22e8-40fe-92f5-0c67f5e0203e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{lllc}\n",
    "\\hline f \\text {-divergence } & \\boldsymbol{f}(\\boldsymbol{u}) & \\boldsymbol{f}^{\\prime}(\\boldsymbol{u}) & 0 \\notin \\text { Domain of } \\boldsymbol{f}^{\\prime}(\\boldsymbol{u}) \\\\\n",
    "\\hline \\alpha \\text {-divergence }(\\alpha \\in(0,1)) & \\left(u^{1-\\alpha}-(1-\\alpha) u-\\alpha\\right) /(\\alpha(\\alpha-1)) & \\left(1-u^{-\\alpha}\\right) / \\alpha & \\checkmark \\\\\n",
    "\\text { Reverse KL }(\\alpha=0) & u \\log u & \\log u+1 & \\checkmark \\\\\n",
    "\\text { Forward KL }(\\alpha=1) & -\\log u & -1 / u & \\checkmark \\\\\n",
    "\\text { JS-divergence } & u \\log u-(u+1) \\log ((u+1) / 2) & \\log (2 u /(1+u)) & \\checkmark \\\\\n",
    "\\hline \\text { Total Variation } & \\frac{1}{2}|u-1| & u>1 ? \\frac{1}{2}:-\\frac{1}{2} & \\mathbf{x} \\\\\n",
    "\\text { Chi-squared } & (u-1)^2 & 2(u-1) & \\mathbf{X} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a8752-8f0a-4042-be94-009496b08b5f",
   "metadata": {},
   "source": [
    "Посколько для обучения любой сети нам нужен только её лосс, нужно это же место и найти. Он считается в методе `dpo_loss`, ниже конкретные места, которые надо поменять:\n",
    "\n",
    "```python\n",
    "pi_logratios = policy_chosen_logps - policy_rejected_logps\n",
    "if reference_free:\n",
    "    ref_logratios = 0\n",
    "else:\n",
    "    ref_logratios = reference_chosen_logps - reference_rejected_logps\n",
    "```\n",
    "\n",
    "на\n",
    "\n",
    "```python\n",
    "pi_ratios = self.divergence(policy_chosen_logps, policy_rejected_logps)\n",
    "ref_ratios = self.divergence(reference_chosen_logps, reference_rejected_logps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3462a4a-f563-4cc8-91d5-31d3037e26f2",
   "metadata": {},
   "source": [
    "В классе уже имплементирован случай, когда считается RKL-div, там уже удобно сделано, ведь там есть логарифм, остаётся их только повычитать. В случае же обычной дивергенции нужно иметь дело с отношением и экспонентой, это взрывает градиенты. Я обошёл это как мог, но взрыв всё равно есть, поэтому я принудительно их клипаю и делаю апкаст . Как выглядят функции можно посмотреть в `utils.py`, то, как я это встроил - в `pipeline.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a83a91-a66a-47ea-b7f5-078790043669",
   "metadata": {},
   "source": [
    "Проверим, что у нас получается примерно то, что надо. Имеем в виду, что при экстремальных $\\alpha$ альфа-дивергенция должна быть похожа на КЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af516707-31a8-4814-b1d7-548998df6113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  1,  1, -5])\n",
      "tensor([ 0.9995,  0.9995,  0.9995, -5.0125], dtype=torch.float64)\n",
      "tensor([  0.7869,   0.7869,   0.7869, -22.3650], dtype=torch.float64)\n",
      "tensor([   0.6321,    0.6321,    0.6321, -147.4132], dtype=torch.float64)\n",
      "tensor([   0.6321,    0.6321,    0.6321, -147.4132], dtype=torch.float64)\n",
      "tensor([ 0.3799,  0.3799,  0.3799, -4.3136], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from utils import (alpha_divergence, KL_divergence, RKL_divergence, JS_divergence)\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([2, 3, 4, 5])\n",
    "b = torch.tensor([1, 2, 3, 10])\n",
    "\n",
    "print(RKL_divergence(a, b))\n",
    "print(alpha_divergence(a, b, alpha=0.001))\n",
    "print(alpha_divergence(a, b, alpha=0.5))\n",
    "print(alpha_divergence(a, b, alpha=1-1e-10))\n",
    "print(KL_divergence(a, b))\n",
    "print(JS_divergence(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5ed1d-8f9f-4e8a-a534-d8ba6a123d52",
   "metadata": {},
   "source": [
    "Ну вроде всё примерно так, а значит, можно запускать цикл и идти пить чай"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56df7d2f-64c7-4bff-be9e-2efd73a03d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "divs = [\n",
    "    RKL_divergence, JS_divergence, KL_divergence\n",
    "]\n",
    "divs += [\n",
    "    partial(lambda x, y, alpha: alpha_divergence(x, y, alpha=alpha), alpha=alpha)\n",
    "    for alpha in [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "]\n",
    "names = [\"rkl\", \"js\", \"kl\", \"a_1\", \"a_3\", \"a_5\", \"a_7\", \"a_9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc9c5f-48e4-4a3a-a78a-4a262a1d400f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipeline import Pipeline\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "\n",
    "for div, name in zip(divs, names):\n",
    "\n",
    "    try:\n",
    "        pipe = Pipeline()\n",
    "        pipe.train(loss_type=\"hinge\", divergence=div)\n",
    "        pipe.evaluate(name, n_samples=100)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        clear_output(True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9fe9d9-800b-4d84-8931-4d26855ce526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar chvfz notebook.tar.gz *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa5c1b-eaac-4a74-a47c-7c950c4971f7",
   "metadata": {},
   "source": [
    "Теперь соберём всё воедино и построим график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fc4a568-7578-4b08-8253-d07c62fc3c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_dfs = [\"kl\", \"rkl\", \"js\", \"a_3\", \"a_5\", \"a_7\", \"a_9\"]\n",
    "summary = pd.concat([pd.read_csv(f\"{df}.csv\") for df in all_dfs])\n",
    "summary = summary.groupby(\"experiment\").mean(\"reward\").sort_values(\"reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b9aea-e668-49de-9b18-3e1b19d5cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "152caad5-9247-442b-9cea-5808fc28fe3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "summary[\"sigma_reward\"] = sigmoid(summary.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68d2c956-6071-4317-be96-753a08684cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>experiment</th>\n",
       "      <th>a_9</th>\n",
       "      <th>a_7</th>\n",
       "      <th>a_5</th>\n",
       "      <th>kl</th>\n",
       "      <th>a_3</th>\n",
       "      <th>js</th>\n",
       "      <th>rkl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <td>2.385917</td>\n",
       "      <td>2.454308</td>\n",
       "      <td>2.515007</td>\n",
       "      <td>2.518397</td>\n",
       "      <td>2.650520</td>\n",
       "      <td>2.658916</td>\n",
       "      <td>2.710398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diversity</th>\n",
       "      <td>4.300991</td>\n",
       "      <td>4.476865</td>\n",
       "      <td>4.250743</td>\n",
       "      <td>4.334102</td>\n",
       "      <td>4.227138</td>\n",
       "      <td>4.264548</td>\n",
       "      <td>3.952406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_reward</th>\n",
       "      <td>0.915747</td>\n",
       "      <td>0.920876</td>\n",
       "      <td>0.925187</td>\n",
       "      <td>0.925421</td>\n",
       "      <td>0.934043</td>\n",
       "      <td>0.934558</td>\n",
       "      <td>0.937637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "experiment         a_9       a_7       a_5        kl       a_3        js  \\\n",
       "reward        2.385917  2.454308  2.515007  2.518397  2.650520  2.658916   \n",
       "diversity     4.300991  4.476865  4.250743  4.334102  4.227138  4.264548   \n",
       "sigma_reward  0.915747  0.920876  0.925187  0.925421  0.934043  0.934558   \n",
       "\n",
       "experiment         rkl  \n",
       "reward        2.710398  \n",
       "diversity     3.952406  \n",
       "sigma_reward  0.937637  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a599f77-ec5f-41b7-8e88-7a6938f08fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = summary.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056d7429-7f40-46fb-b4b3-52639c23c604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "z = np.polyfit(summary[\"sigma_reward\"], summary[\"diversity\"], 2)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "x_new = np.linspace(0.915, 0.94, 50)\n",
    "y_new = f(x_new)\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=summary[\"sigma_reward\"],\n",
    "    y=summary[\"diversity\"],\n",
    "    text=summary[\"experiment\"],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=8),\n",
    "    marker_symbol=\"x\",\n",
    "    marker_color=\"black\",\n",
    "    showlegend=False,\n",
    "    name=\"Experiments\"\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=x_new,\n",
    "    y=y_new,\n",
    "    mode='lines',\n",
    "    showlegend=False,\n",
    "    line = dict(dash='dash')\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "fig.update_layout(\n",
    "    height=500, width=500,\n",
    "    title=\"Reward-Entropy Tradeoff\",\n",
    "    xaxis_title=\"Reward\", yaxis_title=\"Entropy\"\n",
    ")\n",
    "fig.write_html(\"diversities.html\")\n",
    "#fig.show() # плотли иногда не рисуется"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c4d6e9-18a8-4b30-b3fc-a4d2cc6c5f35",
   "metadata": {},
   "source": [
    "<img src=\"https://media.discordapp.net/attachments/674191702906503199/1183868305069588662/image.png?ex=6589e647&is=65777147&hm=ba67361e019a063a44c9e9416a1accbaceacc33605a0690e158c200e39e44d9b&=&format=webp&quality=lossless&width=631&height=654\" style=\"height: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce857b0-6f90-42d2-88b3-7c64e6d0c8c7",
   "metadata": {},
   "source": [
    "График получился не такой красивый, как в статье, и оправданий может быть масса. \n",
    "\n",
    "Во-первых, параметры, вполне возможно, что у меня набор не совсем оптимальный. Я старался скопировать всё так, как там написано, но всё равно разница есть. Как минимум у них gpt4, это другое, как говорится.\n",
    "\n",
    "Во-вторых, у меня всего лишь один запуск, я не успел больше, у меня на это 4 часа после работы (. Если делать нормальный честный эксперимент, то нужно делать несколько запусков и брать среднее, в идеале рисовать errorbar. Я думаю, что в статье так и сделали, потому что больно ровная у них картинка, но может быть и я где-то накосячил в функциях. Хотя простенький тест сверху показал, что должно быть ок\n",
    "\n",
    "Полифит показывает примерно то же самое, но тоже оказался чуть смещён. У меня реворды и дайвёрсити в целом чуть больше, ну опять же у меня чуть-чуть другие условия. В целом видим то же самое - с ростом альфы реворд падает, но тексты более разные. В целом какую дивергенцию ни возьми всё получается, более-менее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7725beeb-4b59-4ed3-a8fd-3f0fe94582a6",
   "metadata": {},
   "source": [
    "### Часть 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad56a5-c71a-44c2-8a7b-870dcc8247a0",
   "metadata": {},
   "source": [
    "Вот тут мне уже не хватает математической подготовки. Ну и не совсем понятно, что считать хорошим результатом. Я бы сказал, что здесь нужно максимизировать и разнообразие, и реворды одновременно, но как именно это можно было бы сделать, я не представляю. Разве что попробовать покрутить гиперпараметры, попридумывать более разнообразных промптов и так далее. Может быть есть какие-то спосообы обогатить модель после её обучения - накидать каких-нибудь аугментаций к новым генерациям модели и попробовать сделать её разнообразнее. Как минимум можно разбавить синонимами, это немного, но хоть что-то. Ещё я читал про другие методы, типа PPO, но они тоже уже придуманы. Может быть есть какие-то другие виды дивергенций, но я кроме КЛ ни одной не знаю"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
